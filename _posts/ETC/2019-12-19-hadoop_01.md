---
title: "Hadoop 01 - 가상머신에 호튼웍스 샌드박스 설치"
categories: ETC
tags: Hadoop
header:
  overlay_image: /assets/img/wallpaper.jpg
  overlay_filter: 0.2 # same as adding an opacity of 0.5 to a black background
---

# Virtual Box에 Hortonworks Sandbox 설치하기

## Environment

- OS : macOS Mojave 10.14.6 ver
- RAM : 16GB


## 1.Virtual Box 설치

- [Virtual Box](https://www.virtualbox.org/wiki/Downloads) - OS에 맞는 `Virtual Box` 다운로드 및 설치

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_01-1.png){: .align-center}

- Mac OS 에서 Virtual Box 설치 실패 시 참조  
https://hongku.tistory.com/64

<br>

## 2.HDP(Hortonworks Data Platform) 설치

- [HDP 2.6.5 다운로드](https://downloads-hortonworks.akamaized.net/sandbox-hdp-2.6.5/HDP_2.6.5_virtualbox_180626.ova) - 약 15GB

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-1.png){: .align-center}

다운로드받은 `HDP`를 실행합니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-2.png){: .align-center}

`가져오기`를 클릭합니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-3.png){: .align-center}

약간의 시간이 소요됩니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-4.png){: .align-center}

`Virutal Box`에 `HDP`가 정상적으로 볼러와졌다면 `시작` 버튼을 클릭합니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-5.png){: .align-center}

이번에도 약간의 시간이 소요됩니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-6.png){: .align-center}

- Welcome Screen : http://localhost:1080
- SSH : http://localhost:4200

접속 정보를 확인합니다.


<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-7.png){: .align-center}

웹 브라우저에서 Welcome Screen에 접속되면 `HDP` 설치가 정상적으로 된 것입니다. `LAUNCH DASHBOARD` 버튼을 누르고 Username, Password에 모두 `maria_dev`를 입력하여 로그인합니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_02-8.png){: .align-center}

Ambari 대시보드가 출력됩니다.


## 3.하둡에 데이터 임포트하기

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-1.png){: .align-center}

- 하둡에 임포트할 데이터 예제를 [Grouplens-Datasets](https://grouplens.org/datasets/movielens/)에서 `ml-100k.zip` 다운로드합니다. 압축 파일 내에 `u.data`와 `u.item`파일을 하둡에 임포트해보겠습니다. `u.data`는 영화에 대한 평점이 담겨 있는 `tab`으로 구분된 데이터이며, `u.item`은 영화 이름 등이 담겨 있는 `|(pipe)`로 구분된 데이터입니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-2.png){: .align-center}

우측 상단 메뉴 아이콘을 눌러 `Hive View`을 눌러줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-3.png){: .align-center}

Upload Table 탭을 눌러줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-4.png){: .align-center}

설정 버튼을 눌러줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-5.png){: .align-center}

`Field Delimiter`를 9번 항목으로 설정해줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-6.png){: .align-center}

파일선택을 눌러줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-7.png){: .align-center}

`u.data`파일을 업로드합니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-8.png){: .align-center}

테이블 명과 필드 명을 설정해줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-9.png){: .align-center}

같은 방식으로 두 번째 데이터 업로드를 진행합니다. 이번엔 `Field Delimiter`를 124번 항목으로 설정해줍니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-10.png){: .align-center}

파일선택 버튼을 눌러 `u.item`파일을 업로드합니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_03-11.png){: .align-center}

마찬가지로 테이블 명과 필드 명을 설정해줍니다.


<br>

## 4.Hive로 데이터 조회하기

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_04-1.png){: .align-center}

`Query` 탭으로 이동해 SQL 쿼리를 작성합니다. 사람들이 평점을 많이 남긴 순으로 영화 리스트를 출력하겠습니다.

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_04-2.png){: .align-center}

쿼리 결과를 출력합니다. `movie_id`가 `50`인 영화가 가장 많은 리뷰를 가지고 있는 것을 확인했습니다.


```sql
SELECT movie_id, count(movie_id) as ratingCount
FROM ratings
GROUP BY movie_id
ORDER BY ratingCount DESC;
```

<br>

![PNG](/assets/img/post_img/2019-12-19-hadoop_01/img_04-3.png){: .align-center}

`movie_id`가 `50`인 영화의 제목을 조회한 결과 스타워즈인 것을 확인할 수 있습니다.

```sql
SELECT name
FROM movie_names
WHERE movie_id = 50;
```
